---
title: "Knapsack"
author: "Annalena Erhard, Ruben J Munoz, Maximilian Pfundstein"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Knapsack}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE, eval = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r, include = FALSE, eval = TRUE}
library(binaryLogic)
library(knapsack)
library(ggplot2)

load("../data/benchmark.RData")

set.seed(42)
n <- 2000
knapsack_objects <-
  data.frame(
    w=sample(1:4000, size = n, replace = TRUE), v=runif(n = n, 0, 10000)
)
```

## Questions

### How much time does it takes to run the algorithm for n = 16 objects?

```{r, include = TRUE, eval = FALSE}
print(system.time(brute_force_knapsack(x = knapsack_objects[1:16,], W = 3500)))
```

```
user  system elapsed 
 14.657   0.084  14.767
```

### How much time does it takes to run the algorithm for n = 500 objects?

```{r, include = TRUE, eval = FALSE}
print(system.time(dynamic_knapsack(x = knapsack_objects[1:500,], W = 3500)))
```

```
user  system elapsed 
 18.113   0.088  18.225
```

### How much time does it takes to run the algorithm for n = 1000000 objects?

```{r, include = TRUE, eval = FALSE}
print(system.time(greedy_knapsack(x = knapsack_objects[1:1000000,], W = 3500)))
```

```
user  system elapsed 
  1.217   0.056   1.275
```

### What performance gain could you get by trying to improving your code?
There was not much left to improve, we used apply functions straight away to avoid the slowness of common loops. Therefore please skip right to the next chapter.

### What performance gain could you get by parallelizing brute force search?
For performing a benchmark table, we ran the bruteforce method with 2..18 items each single core and parallel. The code we used for this is:

```{r, include = TRUE, eval = FALSE}
benchmark.df = data.frame(noItems=integer(),
                 single=double(),
                 parallel=double())

for (i in c(2:18)) {
  singleBench = sum(system.time(brute_force_knapsack(x = knapsack_objects[1:i,], W = 3500)))
  parallelBench = sum(system.time(brute_force_knapsack(x = knapsack_objects[1:i,], W = 3500, parallel = TRUE)))
  benchmark.df = rbind(benchmark.df, data.frame(noItems = i, single = singleBench, parallel = parallelBench))
}
```

The dataframe looks like this:

```{r, include = TRUE, eval = TRUE}
print(benchmark.df)
```

The plotted data looks like this:

```{r, echo = FALSE, eval = TRUE}
ggplot() + geom_line(aes(x=benchmark.df$noItems, y=benchmark.df$single, color = "Parallel")) + geom_line(aes(x=benchmark.df$noItems, y=benchmark.df$parallel, color="Single")) + theme_light() + labs(x = "Number of Items", y = "Seconds") + ggtitle("Benchmark of brute_force_knapsack() with Single and Multi Cores") + scale_color_manual(values = c('Parallel' = 'green', 'Single' = 'orange')) + labs(color = 'Legend')
```

We can see, that around an item count of 12, the parallelized version has a better performance. The reason why this performance increase only applies at an item count around 12 is the overhead for spinning up thread for parallelization.
